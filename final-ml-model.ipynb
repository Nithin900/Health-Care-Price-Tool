{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ccbe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ace_tools_open in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ace_tools_open) (2.2.3)\n",
      "Requirement already satisfied: itables in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ace_tools_open) (2.3.0)\n",
      "Requirement already satisfied: IPython in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ace_tools_open) (8.29.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from IPython->ace_tools_open) (0.4.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from itables->ace_tools_open) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->ace_tools_open) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->ace_tools_open) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->ace_tools_open) (2024.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jedi>=0.16->IPython->ace_tools_open) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->ace_tools_open) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->ace_tools_open) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->IPython->ace_tools_open) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->IPython->ace_tools_open) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->IPython->ace_tools_open) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\nithi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ace_tools_open\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc0b518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imblearn in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn->imblearn) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn->imblearn) (1.6.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\nithi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78036a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nithi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from xgboost) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\nithi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb6ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a624744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_18196\\960638996.py:2: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\nithi\\OneDrive - St. Clair College\\322-capstone-project\\benefits-and-cost-sharing-puf\\cleaned_benefits_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Load Datasets\n",
    "df = pd.read_csv(r\"C:\\Users\\nithi\\OneDrive - St. Clair College\\322-capstone-project\\benefits-and-cost-sharing-puf\\cleaned_benefits_data.csv\")\n",
    "group_ref = pd.read_csv(r\"C:\\Users\\nithi\\Downloads\\ML-model\\BENEFIT_GROUPED.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57534a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BusinessYear', 'StateCode', 'IssuerId', 'SourceName', 'ImportDate',\n",
       "       'StandardComponentId', 'PlanId', 'BenefitName', 'CopayOutofNet',\n",
       "       'CoinsOutofNet', 'IsEHB', 'IsCovered', 'QuantLimitOnSvc', 'LimitQty',\n",
       "       'LimitUnit', 'Explanation', 'EHBVarReason', 'IsExclFromInnMOOP',\n",
       "       'IsExclFromOonMOOP', 'CoinsInnTier1', 'CoinsInnTier2', 'CopayInnAmount',\n",
       "       'CopayInnText', 'CopayInnAmount_2', 'CopayInnText_2', 'MOOP',\n",
       "       'MOOP_Rank', 'Coverage_Rank', 'Cost_Rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66480b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Drop Irrelevant Columns\n",
    "irrelevant_cols = [\"BusinessYear\", \"IssuerId\", \"StandardComponentId\", \"PlanId\", \"SourceName\", \"ImportDate\",'CopayInnText_2', 'MOOP_Rank','Coverage_Rank', 'Cost_Rank', 'BenefitGroupID','LimitQty', 'LimitUnit', 'Explanation',\n",
    "       'EHBVarReason','QuantLimitOnSvc','CopayInnText']\n",
    "df.drop(columns=[col for col in irrelevant_cols if col in df.columns], inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf399a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StateCode', 'BenefitName', 'CopayOutofNet', 'CoinsOutofNet', 'IsEHB',\n",
       "       'IsCovered', 'IsExclFromInnMOOP', 'IsExclFromOonMOOP', 'CoinsInnTier1',\n",
       "       'CoinsInnTier2', 'CopayInnAmount', 'CopayInnAmount_2', 'MOOP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1990a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Merge Datasets on Cleaned 'BenefitName'\n",
    "df[\"BenefitName\"] = df[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "group_ref[\"BenefitName\"] = group_ref[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "df = pd.merge(df, group_ref, how=\"left\", on=\"BenefitName\")\n",
    "\n",
    "# Drop rows with missing target group info\n",
    "df.dropna(subset=[\"BenefitGroupID\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "001fe244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateCode</th>\n",
       "      <th>BenefitName</th>\n",
       "      <th>CopayOutofNet</th>\n",
       "      <th>CoinsOutofNet</th>\n",
       "      <th>IsEHB</th>\n",
       "      <th>IsCovered</th>\n",
       "      <th>IsExclFromInnMOOP</th>\n",
       "      <th>IsExclFromOonMOOP</th>\n",
       "      <th>CoinsInnTier1</th>\n",
       "      <th>CoinsInnTier2</th>\n",
       "      <th>CopayInnAmount</th>\n",
       "      <th>CopayInnAmount_2</th>\n",
       "      <th>MOOP</th>\n",
       "      <th>BenefitGroupID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Routine Dental Services (Adult)</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>20.00%</td>\n",
       "      <td>No</td>\n",
       "      <td>Covered</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.783632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Dental Check-Up For Children</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>15.00%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Covered</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.783632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Basic Dental Care - Child</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>60.00%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Covered</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.783632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Orthodontia - Child</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>70.00%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Covered</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.783632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Major Dental Care - Child</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>70.00%</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Covered</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.783632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StateCode                      BenefitName   CopayOutofNet CoinsOutofNet  \\\n",
       "0        AK  Routine Dental Services (Adult)  Not Applicable        20.00%   \n",
       "1        AK     Dental Check-Up For Children  Not Applicable        15.00%   \n",
       "2        AK        Basic Dental Care - Child  Not Applicable        60.00%   \n",
       "3        AK              Orthodontia - Child  Not Applicable        70.00%   \n",
       "4        AK        Major Dental Care - Child  Not Applicable        70.00%   \n",
       "\n",
       "  IsEHB IsCovered IsExclFromInnMOOP IsExclFromOonMOOP  CoinsInnTier1  \\\n",
       "0    No   Covered               Yes               Yes           20.0   \n",
       "1   Yes   Covered                No                No           15.0   \n",
       "2   Yes   Covered                No                No           60.0   \n",
       "3   Yes   Covered                No                No           70.0   \n",
       "4   Yes   Covered                No                No           70.0   \n",
       "\n",
       "   CoinsInnTier2  CopayInnAmount  CopayInnAmount_2  MOOP  BenefitGroupID  \n",
       "0      10.783632             0.0               0.0  20.0            86.0  \n",
       "1      10.783632             0.0               0.0  15.0            16.0  \n",
       "2      10.783632             0.0               0.0  60.0             7.0  \n",
       "3      10.783632             0.0               0.0  70.0            61.0  \n",
       "4      10.783632             0.0               0.0  70.0            47.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb6f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load cleaned dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\nithi\\OneDrive - St. Clair College\\322-capstone-project\\benefits-and-cost-sharing-puf\\cleaned_benefits_data.csv\", low_memory=False, nrows=30000)\n",
    "\n",
    "# Normalize BenefitName and merge group info\n",
    "df[\"BenefitName\"] = df[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "group_ref = pd.read_csv(\"BENEFIT_GROUPED.csv\")\n",
    "group_ref[\"BenefitName\"] = group_ref[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "df = pd.merge(df, group_ref, how=\"left\", on=\"BenefitName\")\n",
    "df.dropna(subset=[\"BenefitGroupID\"], inplace=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# STEP 1: Numeric conversion + clean up\n",
    "# ---------------------------------------\n",
    "cost_cols = [\n",
    "    \"CopayInnAmount\", \"CopayInnAmount_2\", \"CopayOutofNet\",\n",
    "    \"CoinsInnTier1\", \"CoinsInnTier2\", \"CoinsOutofNet\", \"MOOP\"\n",
    "]\n",
    "\n",
    "# Replace \"Not Applicable\" with 0 and clean non-numeric\n",
    "for col in cost_cols:\n",
    "    df[col] = df[col].astype(str).str.replace(\"Not Applicable\", \"0\", case=False)\n",
    "    df[col] = df[col].str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# STEP 2: Add binary flags for zero-values\n",
    "# ---------------------------------------\n",
    "for col in cost_cols:\n",
    "    df[f\"{col}_was_zero\"] = (df[col] == 0).astype(int)\n",
    "\n",
    "# ---------------------------------------\n",
    "# STEP 3: Clip outliers at 99th percentile\n",
    "# ---------------------------------------\n",
    "for col in cost_cols:\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], 0, upper)\n",
    "\n",
    "# ---------------------------------------\n",
    "# STEP 4: Impute missing values with median\n",
    "# ---------------------------------------\n",
    "df[cost_cols] = df[cost_cols].fillna(df[cost_cols].median())\n",
    "\n",
    "# ---------------------------------------\n",
    "# STEP 5: Encode boolean fields\n",
    "# ---------------------------------------\n",
    "bool_map = {\"Yes\": 1, \"No\": 0, \"Covered\": 1, \"Not Covered\": 0}\n",
    "for col in [\"IsEHB\", \"IsCovered\", \"IsExclFromInnMOOP\", \"IsExclFromOonMOOP\"]:\n",
    "    df[col] = df[col].map(bool_map).fillna(0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e92ae77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# STEP 6: Encode target labels\n",
    "# ---------------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"GroupLabel\"] = le.fit_transform(df[\"BenefitGroupID\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ecd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------\n",
    "# STEP 7: Scale features and combine\n",
    "# ---------------------------------------\n",
    "scaler = StandardScaler()\n",
    "scaled_costs = scaler.fit_transform(df[cost_cols])\n",
    "scaled_costs_df = pd.DataFrame(scaled_costs, columns=cost_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c143b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine with zero flags and booleans\n",
    "flag_cols = [f\"{col}_was_zero\" for col in cost_cols]\n",
    "X = pd.concat([\n",
    "    scaled_costs_df.reset_index(drop=True),\n",
    "    df[flag_cols].reset_index(drop=True),\n",
    "    df[[\"IsEHB\", \"IsCovered\", \"IsExclFromInnMOOP\", \"IsExclFromOonMOOP\"]].reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "y = df[\"GroupLabel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a16fdaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m      8\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[0;32m      9\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     12\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m sm \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, k_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfit_resample(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     16\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 3. Predict on Test Set\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# 2. Initialize and Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,class_weight='balanced',\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sm = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 3. Predict on Test Set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"✅ Random Forest Classifier Performance\")\n",
    "print(\"Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
    "print(\"F1 Score (macro):\", round(f1, 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupLabel\n",
      "81    512\n",
      "13    511\n",
      "6     511\n",
      "56    511\n",
      "43    511\n",
      "     ... \n",
      "53      6\n",
      "62      6\n",
      "63      6\n",
      "64      6\n",
      "32      6\n",
      "Name: count, Length: 106, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5829f617",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922aaaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Temp\\ipykernel_20008\\4153715621.py:10: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"C:\\Users\\nithi\\OneDrive - St. Clair College\\322-capstone-project\\benefits-and-cost-sharing-puf\\cleaned_benefits_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned Random Forest Model with Valid CategoryID\n",
      "Accuracy: 25.89 %\n",
      "F1 Score (macro): 0.2477\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.20      0.16     12596\n",
      "           1       0.94      0.31      0.46     28349\n",
      "           2       0.36      0.70      0.48      9566\n",
      "           3       0.17      0.18      0.18     14599\n",
      "           4       0.20      0.54      0.29     14599\n",
      "           5       0.47      0.26      0.33     14981\n",
      "           6       0.62      0.01      0.03     26289\n",
      "           7       0.31      0.39      0.34     12276\n",
      "           8       0.18      0.31      0.23     11690\n",
      "           9       0.20      0.23      0.22     17761\n",
      "          10       0.39      0.02      0.05     14599\n",
      "          11       0.35      0.17      0.23     17519\n",
      "          12       0.14      0.49      0.22      8759\n",
      "\n",
      "    accuracy                           0.26    203583\n",
      "   macro avg       0.35      0.29      0.25    203583\n",
      "weighted avg       0.41      0.26      0.24    203583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 2. Load data\n",
    "df = pd.read_csv(r\"C:\\Users\\nithi\\OneDrive - St. Clair College\\322-capstone-project\\benefits-and-cost-sharing-puf\\cleaned_benefits_data.csv\")\n",
    "group_map = pd.read_csv(r\"C:\\Users\\nithi\\Downloads\\ML-model\\benefit_supercategories_cleaned.csv\")\n",
    "\n",
    "# 3. Merge SuperCategoryID\n",
    "df[\"BenefitName\"] = df[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "group_map[\"BenefitName\"] = group_map[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "df = pd.merge(df, group_map[[\"BenefitName\", \"SuperCategoryID\"]], how=\"left\", on=\"BenefitName\")\n",
    "\n",
    "# ❌ Remove invalid CategoryIDs\n",
    "df = df[df[\"SuperCategoryID\"].notna()]\n",
    "df = df[df[\"SuperCategoryID\"] != -1]\n",
    "df[\"SuperCategoryID\"] = df[\"SuperCategoryID\"].astype(int)\n",
    "\n",
    "# 4. Clean cost columns\n",
    "cost_cols = [\n",
    "    \"CopayInnAmount\", \"CopayInnAmount_2\", \"CopayOutofNet\",\n",
    "    \"CoinsInnTier1\", \"CoinsInnTier2\", \"CoinsOutofNet\", \"MOOP\"\n",
    "]\n",
    "\n",
    "for col in cost_cols:\n",
    "    df[col] = df[col].astype(str).str.replace(\"Not Applicable\", \"0\", case=False)\n",
    "    df[col] = df[col].str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df[f\"{col}_was_zero\"] = (df[col] == 0).astype(int)\n",
    "    df[col] = np.clip(df[col], 0, df[col].quantile(0.99))\n",
    "\n",
    "df[cost_cols] = df[cost_cols].fillna(df[cost_cols].median())\n",
    "\n",
    "# 5. Encode binary features\n",
    "bool_map = {\"Yes\": 1, \"No\": 0, \"Covered\": 1, \"Not Covered\": 0}\n",
    "bool_fields = [\"IsEHB\", \"IsCovered\", \"IsExclFromInnMOOP\", \"IsExclFromOonMOOP\"]\n",
    "for col in bool_fields:\n",
    "    df[col] = df[col].map(bool_map).fillna(0).astype(int)\n",
    "\n",
    "# 6. Prepare features\n",
    "binary_flags = [f\"{col}_was_zero\" for col in cost_cols]\n",
    "features = cost_cols + binary_flags + bool_fields\n",
    "X = df[features]\n",
    "y = df[\"SuperCategoryID\"]\n",
    "\n",
    "# 7. Scale & split\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 8. Train Random Forest with best hyperparams\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=20,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 9. Predict & Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"✅ Cleaned Random Forest Model with Valid CategoryID\")\n",
    "print(\"Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
    "print(\"F1 Score (macro):\", round(f1, 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087b173",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa2124c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [15:59:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Model Saved\n",
      "Accuracy: 89.84 %\n",
      "F1 Score (macro): 0.8964\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.30      0.46     12596\n",
      "           1       1.00      1.00      1.00     28349\n",
      "           2       0.97      0.94      0.95      9566\n",
      "           3       1.00      1.00      1.00     14599\n",
      "           4       0.96      0.94      0.95     14599\n",
      "           5       0.96      0.98      0.97     14981\n",
      "           6       0.65      0.92      0.76     26289\n",
      "           7       1.00      1.00      1.00     12276\n",
      "           8       0.88      0.96      0.92     11690\n",
      "           9       0.83      0.71      0.76     17761\n",
      "          10       1.00      1.00      1.00     14599\n",
      "          11       0.89      0.85      0.87     17519\n",
      "          12       1.00      1.00      1.00      8759\n",
      "\n",
      "    accuracy                           0.90    203583\n",
      "   macro avg       0.93      0.89      0.90    203583\n",
      "weighted avg       0.91      0.90      0.89    203583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_csv(r\"C:\\Users\\nithi\\Downloads\\ML-model\\cleaned_benefits_data.csv\", low_memory=False)\n",
    "group_map = pd.read_csv(r\"C:\\Users\\nithi\\Downloads\\ML-model\\benefit_supercategories_cleaned.csv\", low_memory=False)\n",
    "\n",
    "# Merge SuperCategoryID\n",
    "df[\"BenefitName\"] = df[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "group_map[\"BenefitName\"] = group_map[\"BenefitName\"].astype(str).str.strip().str.title()\n",
    "df = pd.merge(df, group_map[[\"BenefitName\", \"SuperCategoryID\"]], on=\"BenefitName\", how=\"left\")\n",
    "df = df[df[\"SuperCategoryID\"].notna() & (df[\"SuperCategoryID\"] != -1)]\n",
    "df[\"SuperCategoryID\"] = df[\"SuperCategoryID\"].astype(int)\n",
    "\n",
    "# Normalize cost-related fields\n",
    "cost_cols = [\n",
    "    \"CopayInnAmount\", \"CopayInnAmount_2\", \"CopayOutofNet\",\n",
    "    \"CoinsInnTier1\", \"CoinsInnTier2\", \"CoinsOutofNet\", \"MOOP\"\n",
    "]\n",
    "for col in cost_cols:\n",
    "    df[col] = df[col].astype(str).str.replace(\"Not Applicable\", \"0\", case=False)\n",
    "    df[col] = df[col].str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df[f\"{col}_was_zero\"] = (df[col] == 0).astype(int)\n",
    "    df[col] = np.clip(df[col], 0, df[col].quantile(0.99))\n",
    "df[cost_cols] = df[cost_cols].fillna(df[cost_cols].median())\n",
    "\n",
    "# Encode boolean fields\n",
    "bool_map = {\"Yes\": 1, \"No\": 0, \"Covered\": 1, \"Not Covered\": 0}\n",
    "bool_fields = [\"IsEHB\", \"IsCovered\", \"IsExclFromInnMOOP\", \"IsExclFromOonMOOP\"]\n",
    "for col in bool_fields:\n",
    "    df[col] = df[col].map(bool_map).fillna(0).astype(int)\n",
    "\n",
    "# Prepare numeric features\n",
    "binary_flags = [f\"{col}_was_zero\" for col in cost_cols]\n",
    "numeric_features = cost_cols + binary_flags + bool_fields\n",
    "X_numeric = df[numeric_features]\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_numeric)\n",
    "y = df[\"SuperCategoryID\"]\n",
    "\n",
    "# Vectorizer configuration (selecting best based on previous results)\n",
    "vectorizer = TfidfVectorizer(max_features=50, ngram_range=(1, 2))\n",
    "benefit_vectors = vectorizer.fit_transform(df[\"BenefitName\"])\n",
    "X_combined = hstack([benefit_vectors, X_scaled])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train final model\n",
    "model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=len(np.unique(y)),\n",
    "    eval_metric=\"mlogloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model and transformers\n",
    "joblib.dump(model, \"xgb_benefit_classifier.pkl\")\n",
    "joblib.dump(vectorizer, \"benefitname_vectorizer.pkl\")\n",
    "joblib.dump(scaler, \"numeric_scaler.pkl\")\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"✅ Final Model Saved\")\n",
    "print(\"Accuracy:\", round(acc * 100, 2), \"%\")\n",
    "print(\"F1 Score (macro):\", round(f1, 4))\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c048365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 16:02:49.032 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.034 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.128 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\nithi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-06 16:02:49.129 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.138 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.139 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.142 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-06 16:02:49.144 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.145 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.146 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.147 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.154 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.156 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.158 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.159 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.160 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.161 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.162 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.163 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.165 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.166 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.167 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.169 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.173 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.175 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.176 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.177 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.178 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.179 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.180 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.182 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.183 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.184 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.185 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.186 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.187 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.188 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.189 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.190 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.191 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.193 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.195 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.200 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.205 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-06 16:02:49.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load the model and transformers\n",
    "model = joblib.load(r\"C:\\Users\\nithi\\Downloads\\ML-model\\xgb_benefit_classifier.pkl\")\n",
    "vectorizer = joblib.load(r\"C:\\Users\\nithi\\Downloads\\ML-model\\benefitname_vectorizer.pkl\")\n",
    "scaler = joblib.load(r\"C:\\Users\\nithi\\Downloads\\ML-model\\numeric_scaler.pkl\")\n",
    "\n",
    "st.set_page_config(page_title=\"Healthcare Benefit Classifier\", layout=\"wide\")\n",
    "st.title(\"🩺 Healthcare Benefit Classification Tool\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "### 🎯 Objective\n",
    "Automatically categorize a health benefit into one of the key patient-centric categories (e.g., Dental, Emergency, Maternity).\n",
    "\"\"\")\n",
    "\n",
    "with st.form(\"benefit_form\"):\n",
    "    st.subheader(\"Enter Benefit Details\")\n",
    "    benefit_name = st.text_input(\"Benefit Name\", \"Basic Dental Care - Adult\")\n",
    "\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        copay_inn = st.number_input(\"Copay In-Network ($)\", value=0.0)\n",
    "        coins_inn = st.number_input(\"Coinsurance In-Network (%)\", value=0.0)\n",
    "    with col2:\n",
    "        copay_out = st.number_input(\"Copay Out-of-Network ($)\", value=0.0)\n",
    "        coins_out = st.number_input(\"Coinsurance Out-of-Network (%)\", value=0.0)\n",
    "    with col3:\n",
    "        moop = st.number_input(\"Max Out-of-Pocket ($)\", value=0.0)\n",
    "\n",
    "    is_ehb = st.selectbox(\"Is EHB?\", [\"Yes\", \"No\"])\n",
    "    is_covered = st.selectbox(\"Is Covered?\", [\"Covered\", \"Not Covered\"])\n",
    "    is_excl_inn = st.selectbox(\"Excluded from In-Network MOOP?\", [\"Yes\", \"No\"])\n",
    "    is_excl_oon = st.selectbox(\"Excluded from Out-of-Network MOOP?\", [\"Yes\", \"No\"])\n",
    "\n",
    "    submitted = st.form_submit_button(\"Classify Benefit\")\n",
    "\n",
    "if submitted:\n",
    "    # Preprocess features\n",
    "    bool_map = {\"Yes\": 1, \"No\": 0, \"Covered\": 1, \"Not Covered\": 0}\n",
    "    numeric_data = pd.DataFrame([{\n",
    "        \"CopayInnAmount\": copay_inn,\n",
    "        \"CoinsInnTier1\": coins_inn,\n",
    "        \"CopayOutofNet\": copay_out,\n",
    "        \"CoinsOutofNet\": coins_out,\n",
    "        \"MOOP\": moop,\n",
    "        \"CopayInnAmount_was_zero\": int(copay_inn == 0),\n",
    "        \"CoinsInnTier1_was_zero\": int(coins_inn == 0),\n",
    "        \"CopayOutofNet_was_zero\": int(copay_out == 0),\n",
    "        \"CoinsOutofNet_was_zero\": int(coins_out == 0),\n",
    "        \"MOOP_was_zero\": int(moop == 0),\n",
    "        \"IsEHB\": bool_map[is_ehb],\n",
    "        \"IsCovered\": bool_map[is_covered],\n",
    "        \"IsExclFromInnMOOP\": bool_map[is_excl_inn],\n",
    "        \"IsExclFromOonMOOP\": bool_map[is_excl_oon]\n",
    "    }])\n",
    "\n",
    "    X_scaled = scaler.transform(numeric_data)\n",
    "    X_text = vectorizer.transform([benefit_name])\n",
    "    X_final = hstack([X_text, X_scaled])\n",
    "\n",
    "    prediction = model.predict(X_final)[0]\n",
    "    categories = [\n",
    "        \"Dental\", \"Mental Health\", \"Emergency\", \"Maternity\",\n",
    "        \"Primary Care\", \"Pharmacy\", \"Hospital\", \"Other\",\n",
    "        \"Vision\", \"Specialty Care\", \"Behavioral Health\", \"Preventive Care\"\n",
    "    ]\n",
    "\n",
    "    st.success(f\"✅ Predicted Category: **{categories[prediction]}**\")\n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "    ### 🏥 Why This Helps Patients\n",
    "    - **Simplifies Plan Comparison**: Grouping helps patients compare benefits side-by-side.\n",
    "    - **Feeds Recommendation Engines**: Used in matching plans with patient conditions.\n",
    "    - **Aids Regulators**: Classifies benefits to verify EHB compliance.\n",
    "    - **Saves Time**: Reduces the manual work of benefit categorization.\n",
    "    \"\"\")\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.caption(\"Built with ❤️ using Streamlit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb644ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
